{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03e48579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# by default, it's recognised as a tool\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool, InjectedToolCallId\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KEY\")\n",
    "\n",
    "\n",
    "# State is the FIRST thing to define in a graph\n",
    "class State(TypedDict):\n",
    "    # Using a list appends incoming messages instead of overwriting the existing messages\n",
    "    # Docs for add_messages: https://langchain-ai.github.io/langgraph/reference/graphs/#langgraph.graph.message.add_messages\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str\n",
    "\n",
    "\n",
    "web_search_tool = TavilySearch(max_results=2)\n",
    "\n",
    "\n",
    "@tool\n",
    "def human_assistance(name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]) -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt({\n",
    "        \"question\": \"Is this correct?\",\n",
    "        \"name\": name,\n",
    "        \"birthday\": birthday\n",
    "    })\n",
    "\n",
    "    if human_response.get('correct', '').lower().startswith('y'):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "    \n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "\n",
    "    return Command(update=state_update)\n",
    "\n",
    "\n",
    "tools = [\n",
    "    web_search_tool,\n",
    "    human_assistance\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0dc9b50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = init_chat_model(\n",
    "    \"qwen2.5:7b\",\n",
    "    model_provider=\"ollama\",\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# Reassignment is required to use the tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "# Graph !== llm, the graph is just a outline of what components to call,\n",
    "# the nodes will then invoke the llm\n",
    "def chatbot_node(state: State):\n",
    "    # Because we will be interrupting during tool execution,\n",
    "    # we disable parallel tool calling to avoid repeating any\n",
    "    # tool invocations when we resume.\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # message = llm.invoke(state[\"messages\"])\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", chatbot_node)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "\n",
    "# Any time a tool is called, we return to the chatbot to decide the next step\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "# sugar syntax for graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b01c4aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  tavily_search (217a4668-1333-4e1c-8045-d9303dac495f)\n",
      " Call ID: 217a4668-1333-4e1c-8045-d9303dac495f\n",
      "  Args:\n",
      "    query: LangGraph release date\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph release date\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"Announcing LangGraph v0.1 & LangGraph Cloud: Running agents at scale ...\", \"url\": \"https://blog.langchain.dev/langgraph-cloud/\", \"content\": \"Announcing LangGraph v0.1 & LangGraph Cloud: Running agents at scale, reliably Our new infrastructure for running agents at scale, LangGraph Cloud, is available in beta. Separate from the langchain package, LangGraph’s core design philosophy is to help developers add better precision and control into agentic workflows, suitable for the complexity of real-world systems. LangGraph Cloud, currently in closed beta, is infrastructure for deploying your LangGraph agents in a scalable, fault tolerant way. LangGraph Cloud: Scalable agent deployment with integrated monitoring To complement the LangGraph framework, we also have a new runtime, LangGraph Cloud, now available in beta, which provides infrastructure purpose-built for deploying agents at scale. LangGraph Cloud also brings a more integrated experience for collaborating on, deploying, and monitoring your agentic app.\", \"score\": 0.3087532, \"raw_content\": null}, {\"title\": \"Releases · langchain-ai/langgraph - GitHub\", \"url\": \"https://github.com/langchain-ai/langgraph/releases\", \"content\": \"GitHub Copilot Write better code with AI GitHub Advanced Security Find and fix vulnerabilities Code Search Find more, search less *   Why GitHub *   GitHub Advanced Security Enterprise-grade security features Search code, repositories, users, issues, pull requests... github-actions This commit was created on GitHub.com and signed with GitHub’s verified signature. Changes since sdk==0.1.69 github-actions This commit was created on GitHub.com and signed with GitHub’s verified signature. github-actions sqlite: Add test for search with list filters (#4747) github-actions github-actions github-actions Add clear cache methods Add namespace to cache keys github-actions Changes since checkpoint==2.0.25 Add namespace to cache keys docs(reference): filter class methods and add missing docstrings (#4463) github-actions Changes since sdk==0.1.66 Update python SDK docstrings (#4602) github-actions github-actions feat: CLI: Add main.py (#4637)\", \"score\": 0.26380843, \"raw_content\": null}], \"response_time\": 1.85}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (b71e57e9-56d8-432f-8fdd-99eb66901e7b)\n",
      " Call ID: b71e57e9-56d8-432f-8fdd-99eb66901e7b\n",
      "  Args:\n",
      "    birthday: \n",
      "    name: LangGraph\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34213f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (b71e57e9-56d8-432f-8fdd-99eb66901e7b)\n",
      " Call ID: b71e57e9-56d8-432f-8fdd-99eb66901e7b\n",
      "  Args:\n",
      "    birthday: \n",
      "    name: LangGraph\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph was released on January 17, 2024. \n",
      "\n",
      "According to the information provided by our human assistant, LangGraph v0.1 and its cloud infrastructure were announced in a blog post titled \"Announcing LangGraph v0.1 & LangGraph Cloud: Running agents at scale...\". This release includes new infrastructure for running agents at scale, which is designed to help developers add better precision and control into agentic workflows.\n",
      "\n",
      "If you need more detailed information or have any other questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "908593bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64e834c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f037cfe-1df8-611e-8006-43c18616cdd4'}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.update_state(config, {\"name\": \"LangGraph (library)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed535b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph (library)', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4069e1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  human_assistance (7cda37f9-3977-40ac-ab96-55e12ecc9184)\n",
      " Call ID: 7cda37f9-3977-40ac-ab96-55e12ecc9184\n",
      "  Args:\n",
      "    query: I need expert guidance for building an AI agent. Can you provide me with the necessary advice?\n",
      "human_response: {'data': \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\"}\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "We, the experts are here to help! We'd recommend you check out LangGraph to build your agent. It's much more reliable and extensible than simple autonomous agents.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Sure, I can provide you with some guidance based on the expert advice we received. They suggested using a tool called LangGraph for building your AI agent. According to them, it is more reliable and easier to extend compared to simpler autonomous agents.\n",
      "\n",
      "Would you like more detailed information about how to use LangGraph or do you have any specific questions regarding its implementation?\n"
     ]
    }
   ],
   "source": [
    "human_response = (\n",
    "    \"We, the experts are here to help! We'd recommend you check out LangGraph to build your agent.\"\n",
    "    \" It's much more reliable and extensible than simple autonomous agents.\"\n",
    ")\n",
    "\n",
    "human_command = Command(resume={\"data\": human_response})\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "391d970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  6 Next:  ()\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  5 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  4 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  3 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  2 Next:  ('tools',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  1 Next:  ('chatbot',)\n",
      "--------------------------------------------------------------------------------\n",
      "Num Messages:  0 Next:  ('__start__',)\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "to_replay = None\n",
    "for state in graph.get_state_history(config):\n",
    "    print(\"Num Messages: \", len(state.values[\"messages\"]), \"Next: \", state.next)\n",
    "    print(\"-\" * 80)\n",
    "    if len(state.values[\"messages\"]) == 6:\n",
    "        # We are somewhat arbitrarily selecting a specific state based on the number of chat messages in the state.\n",
    "        to_replay = state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33fbfbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "{'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f037cfc-46dd-6356-8005-8f3fbcfb96e7'}}\n"
     ]
    }
   ],
   "source": [
    "print(to_replay.next)\n",
    "print(to_replay.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8a982bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "LangGraph was released on January 17, 2024. \n",
      "\n",
      "According to the information provided by our human assistant, LangGraph v0.1 and its cloud infrastructure were announced in a blog post titled \"Announcing LangGraph v0.1 & LangGraph Cloud: Running agents at scale...\". This release includes new infrastructure for running agents at scale, which is designed to help developers add better precision and control into agentic workflows.\n",
      "\n",
      "If you need more detailed information or have any other questions, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "# The `checkpoint_id` in the `to_replay.config` corresponds to a state we've persisted to our checkpointer.\n",
    "for event in graph.stream(None, to_replay.config, stream_mode=\"values\"):\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
